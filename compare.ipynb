{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images(ref, fore):\n",
    "    # Convert images to grayscale\n",
    "    ref_gray = cv2.cvtColor((ref * 255).clip(0,255).astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "    fore_gray = cv2.cvtColor((fore * 255).clip(0,255).astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Use ORB (Oriented FAST and Rotated BRIEF) to detect and compute keypoints and descriptors\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(ref_gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(fore_gray, None)\n",
    "\n",
    "    # Use the BFMatcher to find the best matches between the descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Sort the matches based on their distances\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Get the corresponding points in both images\n",
    "    ref_points = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    fore_points = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Use the RANSAC algorithm to estimate an affine transformation\n",
    "    M, _ = cv2.estimateAffinePartial2D(fore_points, ref_points)\n",
    "\n",
    "    # Apply the transformation to the fore image\n",
    "    aligned_fore = cv2.warpAffine(fore, M, (ref.shape[1], ref.shape[0]))\n",
    "    \n",
    "    refCopy = ref.copy()\n",
    "    mask = aligned_fore.sum(2) == 0\n",
    "    mask = cv2.dilate(mask.astype(np.uint8), np.ones((3, 3), np.uint8), iterations=1).astype(bool)\n",
    "    refCopy[~mask] = aligned_fore[~mask]\n",
    "\n",
    "    return refCopy\n",
    "\n",
    "def get_result(img_id, method):\n",
    "    if method == \"baseline\":\n",
    "        img = plt.imread(f\"baseline/results/{img_id}.png\")[:,:,:3]\n",
    "    elif method == \"ShadowGP\":\n",
    "        img = plt.imread(f\"ShadowGP/extracted_results/{img_id}-output.png\")[:,:,:3]\n",
    "    elif method == \"BlindShadowRemoval\":\n",
    "        img = plt.imread(f\"BlindShadowRemoval/test/{img_id.split('-')[0]}_{img_id}-result.png\")[:,:,:3]\n",
    "        img = img[:236, 1280:1516, :]\n",
    "        gt = plt.imread(f\"gt/{img_id}.png\")[:,:,:3]\n",
    "        img = align_images(gt, img)\n",
    "    elif method == \"classical\":\n",
    "        img = plt.imread(f\"classical/results/{img_id}.png\")[:,:,:3]\n",
    "    else:\n",
    "        return ValueError(\"Method not implemented\")\n",
    "    if img.dtype == np.uint8:\n",
    "        img = img / 255\n",
    "    return img\n",
    "\n",
    "def display_images(images, titles=None):\n",
    "    plt.figure(figsize=(2.5 * len(images), 2.5))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(1, len(images), i+1)\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "def save_comparison(image_sets, titles=None):\n",
    "    with PdfPages('comparison.pdf') as pdf:\n",
    "        for image_set in image_sets:\n",
    "            display_images(image_set, titles)\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "    # compress pdf\n",
    "    os.system(\"gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dNOPAUSE -dQUIET -dBATCH -sOutputFile=comparison_compressed.pdf comparison.pdf\")\n",
    "    os.system(\"rm comparison.pdf && mv comparison_compressed.pdf comparison.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = [path.split(\"/\")[1].split(\".\")[0] for path in glob.glob(\"images/*.png\")]\n",
    "image_ids.sort()\n",
    "\n",
    "image_sets = []\n",
    "for image_index in range(len(image_ids)):\n",
    "    image_id = image_ids[image_index]\n",
    "\n",
    "    try:\n",
    "        input_image = plt.imread(f\"images/{image_id}.png\")\n",
    "        gt = plt.imread(f\"gt/{image_id}.png\")\n",
    "        baseline = get_result(image_id, \"baseline\")\n",
    "        bsr = get_result(image_id, \"BlindShadowRemoval\")\n",
    "        shadowgp = get_result(image_id, \"ShadowGP\")\n",
    "        classical = get_result(image_id, \"classical\")\n",
    "        image_sets.append([input_image, baseline, bsr, classical, shadowgp, gt])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "save_comparison(image_sets, [\"Input\", \"Baseline\", \"BSR\", \"Classical (Ours)\", \"ShadowGP\", \"Ground Truth\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
